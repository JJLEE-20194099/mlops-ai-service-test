{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Scheduling batch transformations with dbt, Airflow, and Feast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview\n",
    "In this notebook, we see how to use dbt to automatically run batch transformations with Airflow, and run materialization once dbt has run its incremental model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../architecture.png\" width=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup the feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply feature repository\n",
    "We first run `feast apply` to register the data sources + features and setup Redis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SNOWFLAKE_DEPLOYMENT_URL=\"[YOUR DEPLOYMENT]\"\n",
      "env: SNOWFLAKE_USER=\"[YOUR USER]\"\n",
      "env: SNOWFLAKE_PASSWORD=\"[YOUR PASSWORD]\"\n",
      "env: SNOWFLAKE_ROLE=\"[YOUR ROLE]\"\n",
      "env: SNOWFLAKE_WAREHOUSE=\"[YOUR WAREHOUSE]\"\n",
      "env: SNOWFLAKE_DATABASE=\"[YOUR DATABASE]\"\n",
      "env: USAGE=False\n"
     ]
    }
   ],
   "source": [
    "%env SNOWFLAKE_DEPLOYMENT_URL=\"[YOUR DEPLOYMENT]\"\n",
    "%env SNOWFLAKE_USER=\"[YOUR USER]\"\n",
    "%env SNOWFLAKE_PASSWORD=\"[YOUR PASSWORD]\"\n",
    "%env SNOWFLAKE_ROLE=\"[YOUR ROLE]\"\n",
    "%env SNOWFLAKE_WAREHOUSE=\"[YOUR WAREHOUSE]\"\n",
    "%env SNOWFLAKE_DATABASE=\"[YOUR DATABASE]\"\n",
    "%env USAGE=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dannychiao/.pyenv/versions/3.8.10/envs/python-3.8/lib/python3.8/site-packages/requests_toolbelt/_compat.py:56: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680\n",
      "  from requests.packages.urllib3.contrib.pyopenssl \\\n",
      "  CREDIT_SCORE\n",
      "0          905\n",
      "object\n",
      "Created feature service \u001b[1m\u001b[32mmodel_v1\u001b[0m\n",
      "\n",
      "Deploying infrastructure for \u001b[1m\u001b[32mcredit_scores_features\u001b[0m\n",
      "Deploying infrastructure for \u001b[1m\u001b[32maggregate_transactions_features\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!feast apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dannychiao/.pyenv/versions/3.8.10/envs/python-3.8/lib/python3.8/site-packages/requests_toolbelt/_compat.py:56: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680\n",
      "  from requests.packages.urllib3.contrib.pyopenssl \\\n"
     ]
    }
   ],
   "source": [
    "from feast import FeatureStore\n",
    "from datetime import datetime\n",
    "\n",
    "store = FeatureStore(repo_path=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch training data from offline store\n",
    "Just to verify the features are in the batch sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        USER_ID            event_timestamp CREDIT_SCORE     7D_AVG_AMT\n",
      "0    C249180629 2021-07-14 09:58:08.149794          645   50057.237500\n",
      "1   C1280683177 2021-07-14 13:53:44.646282          678  509711.838571\n",
      "2   C2110692114 2021-07-14 09:37:42.499745          627  107384.993333\n",
      "3   C2028855118 2021-07-15 08:32:44.047911          694   91279.846000\n",
      "4   C1098256092 2021-07-14 21:19:47.547929          653  203728.274286\n",
      "5    C151864295 2021-07-15 12:02:10.888576          602  152704.650000\n",
      "6    C453965153 2021-07-14 07:45:56.422663          608   55838.750000\n",
      "7    C453965153 2021-07-14 08:30:18.698001          608   56424.637143\n",
      "8   C1538941588 2021-07-14 04:46:01.147905          664   53359.743333\n",
      "9   C2088453634 2021-07-14 12:32:55.807549          630  142781.994286\n",
      "10   C938678606 2021-07-14 20:23:41.073121          735  200350.285714\n",
      "11  C1090163421 2021-07-14 13:29:22.567975          708  140612.327143\n",
      "12  C1664422545 2021-07-14 21:59:44.553418          649  190196.110000\n",
      "13   C940242900 2021-07-14 19:37:52.599105          547  112552.514000\n",
      "14  C1384292928 2021-07-14 14:42:21.717093          611  292003.445000\n",
      "15   C376659788 2021-07-15 11:10:38.042753          733  123175.871667\n",
      "16  C1821183326 2021-07-14 21:47:18.096729          687  122757.326667\n",
      "17  C1217377530 2021-07-15 22:33:07.567269          617  118375.000000\n",
      "18  C1835422371 2021-07-15 06:51:47.340435          680  298976.468571\n",
      "19  C1936612387 2021-07-14 08:03:37.000017          713  104764.644000\n"
     ]
    }
   ],
   "source": [
    "entity_sql = f\"\"\"\n",
    "    SELECT\n",
    "        NAMEORIG as USER_ID,\n",
    "        TIMESTAMP as \"event_timestamp\"\n",
    "    FROM {store.get_data_source(\"transactions_source\").get_table_query_string()}\n",
    "    WHERE TIMESTAMP BETWEEN '2021-07-14' and '2021-07-16'\n",
    "\"\"\"\n",
    "training_df = store.get_historical_features(\n",
    "    entity_df=entity_sql,\n",
    "    features=store.get_feature_service(\"model_v2\"),\n",
    ").to_df()\n",
    "print(training_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Materialize batch features & fetch online features from Redis\n",
    "First we materialize features (which generate the latest values for each entity key from batch sources) into the online store (Redis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dannychiao/.pyenv/versions/3.8.10/envs/python-3.8/lib/python3.8/site-packages/requests_toolbelt/_compat.py:56: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680\n",
      "  from requests.packages.urllib3.contrib.pyopenssl \\\n",
      "Materializing \u001b[1m\u001b[32m2\u001b[0m feature views from \u001b[1m\u001b[32m2021-07-13 20:00:00-04:00\u001b[0m to \u001b[1m\u001b[32m2021-07-15 20:00:00-04:00\u001b[0m into the \u001b[1m\u001b[32mredis\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32mcredit_scores_features\u001b[0m:\n",
      "100%|████████████████████████████████████████████████████| 654482/654482 [00:23<00:00, 27441.97it/s]\n",
      "\u001b[1m\u001b[32maggregate_transactions_features\u001b[0m:\n",
      "100%|██████████████████████████████████████████████████████| 54991/54991 [00:02<00:00, 18921.10it/s]\n"
     ]
    }
   ],
   "source": [
    "!feast materialize 2021-07-14 2021-07-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feast manages what time intervals have been materialized in the registry. So if you schedule regular materialization every hour, you can run `feast materialize-incremental` and Feast will know that all the previous hours were already processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDK based online retrieval\n",
    "Now we can retrieve these materialized features from Redis by directly using the SDK. This is one of the most popular ways to retrieve features with Feast since it allows you to integrate with an existing service (e.g. a Flask) that also handles model inference or pre/post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7D_AVG_AMT  :  [298976.46875]\n",
      "CREDIT_SCORE  :  [680]\n",
      "USER_ID  :  ['C1835422371']\n"
     ]
    }
   ],
   "source": [
    "features = store.get_online_features(\n",
    "    features=store.get_feature_service(\"model_v2\"),\n",
    "    entity_rows=[\n",
    "        {\n",
    "            \"USER_ID\": \"C1835422371\",\n",
    "        }\n",
    "    ],\n",
    ").to_dict()\n",
    "\n",
    "def print_online_features(features):\n",
    "    for key, value in sorted(features.items()):\n",
    "        print(key, \" : \", value)\n",
    "\n",
    "print_online_features(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HTTP based online retrieval\n",
    "We can also retrieve from a deployed feature server. We had previously deployed this with Docker Compose (see [docker-compose.yml](../docker-compose.yml))\n",
    "\n",
    "This can be preferable for many reasons. If you want to build an in-memory cache, caching on a central feature server can allow more effective caching across teams. You can also more centrally manage rate-limiting / access control, upgrade Feast versions independently, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"metadata\": {\n",
      "        \"feature_names\": [\n",
      "            \"USER_ID\",\n",
      "            \"CREDIT_SCORE\"\n",
      "        ]\n",
      "    },\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"event_timestamps\": [\n",
      "                \"1970-01-01T00:00:00Z\"\n",
      "            ],\n",
      "            \"statuses\": [\n",
      "                \"PRESENT\"\n",
      "            ],\n",
      "            \"values\": [\n",
      "                \"C1570470538\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"event_timestamps\": [\n",
      "                \"2021-07-13T22:32:18Z\"\n",
      "            ],\n",
      "            \"statuses\": [\n",
      "                \"PRESENT\"\n",
      "            ],\n",
      "            \"values\": [\n",
      "                570\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "online_request = {\n",
    "  \"feature_service\": \"model_v1\",\n",
    "  \"entities\": {\n",
    "    \"USER_ID\": [\"C1570470538\"]\n",
    "  }\n",
    "}\n",
    "r = requests.post('http://localhost:6566/get-online-features', data=json.dumps(online_request))\n",
    "print(json.dumps(r.json(), indent=4, sort_keys=True))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d634b9af180bcb32a446a43848522733ff8f5bbf0cc46dba1a83bede04bf237"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('python-3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
